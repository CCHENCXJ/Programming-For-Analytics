{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<DIV ALIGN=CENTER>\n",
    "\n",
    "# Data Pre-Processing- Fundamentals-II\n",
    "## Dr. Utku Pamuksuz \n",
    "### pamuksuz@uchicago.edu\n",
    "\n",
    "  \n",
    "</DIV>  \n",
    "-----\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## About\n",
    "\n",
    "In this session, we will examine some high level data pre-processing. \n",
    "Pre-processing is one of the most time consuming tasks \n",
    "among other data mining and machine learning processes. We will analyze the airline data\n",
    "that is frequently used in data science training curriculums. These data are located at\n",
    "canvas, and we will specifically analyze the\n",
    "`flights.csv` file. We will handle missing data, learn categorical value reactions and get familiar with DateTime index. Pandas is a data structure, important and valuable to process/mine data frames efficiently in Python.\n",
    "\n",
    "In the end of this exercise, we will have a dataframe that contains a DateTime Index, no\n",
    "missing values, and has the airport codes represented by categoricals.\n",
    "We could save this data for latter analysis, or being applying learning\n",
    "algorithms.\n",
    "\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We do this to ignore several specific Pandas warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File ../../../Week-6/data/flights.csv does not exist: '../../../Week-6/data/flights.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-1cc5ea9bf6b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mcolumn_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Month'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Day'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dTime'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'aDelay'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dDelay'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Depart'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Arrive'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Distance'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0malldata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'NA'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musecols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0musethis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumn_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File ../../../Week-6/data/flights.csv does not exist: '../../../Week-6/data/flights.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "\n",
    "filename = '../../../Week-6/data/flights.csv'\n",
    "\n",
    "# Read only selected columns for all rows.\n",
    "\n",
    "usethis = (1, 2, 4, 14, 15, 16, 17, 18)\n",
    "column_names = ['Month', 'Day', 'dTime', 'aDelay', 'dDelay', 'Depart', 'Arrive', 'Distance']\n",
    "\n",
    "alldata = pd.read_csv(filename, header=0, na_values=['NA'], usecols=usethis, names=column_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "When we first read a file in Pandas dataframe(df), we will first explore\n",
    "the data. `describe` method\n",
    "provides a statistical summary of the data. In the example below, we have six\n",
    "numerical columns that have minimum and maximum values, as\n",
    "well as basic statistical summaries.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldata.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "### Missing Values\n",
    "\n",
    "One issue, however, is the different number of rows for the different\n",
    "columns. In fact, there are three different values: 5967780, 5736582,\n",
    "and 5723673. We will not want to perform any analysis on a row\n",
    "that does not have a valid departure time, we will first drop any row that does not\n",
    "have a valid value in this column.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop any row that is missing a departure time\n",
    "#axis=0 is row, axis=1 is column\n",
    "\n",
    "alldata.dropna(axis=0, subset=['dTime'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "Now we can explore the number of rows for each column by employing the\n",
    "`count` method. In this case, we see that the `aDelay` column is still\n",
    "missing some values. In this case, we can fill these missing values with\n",
    "another value. There are a number of options for accomplishing this\n",
    "task, including replacing with a default value (for example, we could\n",
    "use the departure delay), interpolation, or even imputation (where we\n",
    "might determine a mean value for flights in this distance range or from\n",
    "the departure airport). In our case, we can simply assume the\n",
    "arrival delay is zero for any missing value.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now display number of 'ok' values for each column.\n",
    "alldata.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now replace missing values (which are all in Arrival Delay column)\n",
    "# with 0, note we could use another value, such as the departure delay.\n",
    "#values={'aDelay':0}\n",
    "\n",
    "alldata.fillna(value=0, axis=0, inplace=True)\n",
    "\n",
    "#values = {'aDelay': 0, 'Distance': 1, 'C': 2, 'D': 3}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "We now create a new df to hold our final data set. In this case,\n",
    "we start by copying over the three columns that won't change.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First create a new DataFrame\n",
    "# For now, simply copy over the columns, but we could\n",
    "# convert them to integers (for number, the number of minutes in the delay)\n",
    "# and change data type to save memory.\n",
    "\n",
    "newdata = alldata[['aDelay', 'dDelay', 'Distance']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "### Categorical Values\n",
    "\n",
    " `describe` method didn't show `Depart`\n",
    "and `Arrive` columns at the outset. Since they are interpreted as\n",
    "string values, Pandas does not perform any statistical analysis of the\n",
    "value. Since there are a limited number of airports that are contained\n",
    "in our data, we can allow Pandas to map the Airport codes contained in\n",
    "the `Depart` and `Arrive` columns to numerical representations by\n",
    "employing [categorical][pdc] values. In this case, we can do this easily\n",
    "by copying these columns over to our new DataFrame, and specifying that\n",
    "they should be converted to type `categorical`.\n",
    "\n",
    "To demonstrate the set of values that we will need to map to\n",
    "categoricals, we can display all unique airport codes in the `Depart`\n",
    "column.\n",
    "\n",
    "-----\n",
    "[pdc]: http://pandas.pydata.org/pandas-docs/stable/categorical.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldata['Depart'].unique()\n",
    "#alldata.dtypes\n",
    "#type (alldata.Depart[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now copy over the departure and Arrival columns, but change data type to categoricals. \n",
    "\n",
    "newdata['Depart'] = alldata['Depart'].astype('category')\n",
    "newdata['Arrive'] = alldata['Arrive'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "### DateTime\n",
    "\n",
    "Last but not least, how do we handle times?. Pandas has strong support for\n",
    "[dates and times][pdt]. In this context, we can create a new\n",
    "`DateTime` column. While it is generally easier to create a `DateTime`\n",
    "column when reading a CSV file, it is not easy to account for missing\n",
    "values during this process. In that case, one could read in the data,\n",
    "clean missing values, and write the data back to a CSV (or other format)\n",
    "file to enable the traditional data parsing to be performed.\n",
    "\n",
    "In this case, however, we will instead create several new columns from\n",
    "the original data set, and use these new columns to create a `DateTime`\n",
    "column. First, we create a new `Year` column, which in this case we hard\n",
    "code to `2001`, which is the year corresponding to these data. Second,\n",
    "we copy over the `Month` and `Day` columns. Finally, we convert the\n",
    "encoded departure time column to an `Hour` and `Min`. Before any new\n",
    "processing, we first display the last few rows of our new DataFrame\n",
    "before computing summary statistics for the new DataFrame to verify our\n",
    "work.\n",
    "\n",
    "-----\n",
    "\n",
    "[pdt]: http://pandas.pydata.org/pandas-docs/stable/timeseries.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdata['Year'] = 2001\n",
    "newdata['Month'] = alldata.Month\n",
    "newdata['Day'] = alldata.Day\n",
    "newdata['Hour'] = (alldata.dTime/100).astype(int)\n",
    "newdata['Min'] = (alldata.dTime - 100*(alldata.dTime/100.).astype(int)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdata.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdata.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### OPTIONAL\n",
    "Now we can turn our attention to creating a `DateTime` column in our new\n",
    "DataFrame. However, in the output of the `describe` method, you should\n",
    "notice that the `Hour` column has a maximum of 24 hours. Our method of\n",
    "creating a `DateTime` value employs the Python [`strftime`][pst] string\n",
    "date/time representation. This representation does not allow values\n",
    "higher than 23 for an hour, hence we have to modify our data. For this\n",
    "demonstration, we will simply subtract one minute. In a production\n",
    "system, you might instead convert the `DateTime` to the next day.\n",
    "\n",
    "Once these columns have been modified appropriately, we create a\n",
    "DateTime by using the `to_datetime` method. We first combine our date\n",
    "and time DataFrame columns into a new string value, and specify the\n",
    "appropriate format string to decode these values. After creating this\n",
    "new column, we indicate that it should be used as the index for the new\n",
    "DateFrame. Finally, we display the last few rows of the new DataFrame to\n",
    "show the values.\n",
    "\n",
    "-----\n",
    "[pst]: http://strftime.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'newdata' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-624f5519d3ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnewdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnewdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHour\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m24\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Min'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m59\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnewdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnewdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHour\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m24\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Hour'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m23\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'newdata' is not defined"
     ]
    }
   ],
   "source": [
    "newdata.loc[newdata.Hour == 24, 'Min'] = 59\n",
    "newdata.loc[newdata.Hour == 24, 'Hour'] = 23\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdata['DTI'] = pdt.o_datetime(newdata.Year * 100000000 + \n",
    "                                newdata.Month * 1000000 + \n",
    "                                newdata.Day * 10000 + \n",
    "                                newdata.Hour * 100 + \n",
    "                                newdata.Min, format=\"%Y%m%d%H%M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdata.set_index('DTI', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdata.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
